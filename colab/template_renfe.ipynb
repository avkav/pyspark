{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/raulcastillabravo/pyspark/blob/main/colab/template_renfe.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"EawdhwUzh1HN"},"source":["# Librerías\n","\n","Ejecutar esta celda siempre al comienzo. Si da error, reiniciar el entorno de ejecución."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Gaf6sUupOka6","outputId":"50e86190-3236-48ba-d5b4-dd012256d8ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,032 kB]\n","Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,648 kB]\n","Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,450 kB]\n","Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,400 kB]\n","Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,595 kB]\n","Fetched 16.5 MB in 2s (7,737 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n","tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n","tar: Error is not recoverable: exiting now\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"]}],"source":["!sudo apt update\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n","!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n","!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n","!pip install -q findspark\n","!pip install pyspark\n","!pip install py4j\n","\n","# Clone datasets\n","!apt-get install git\n","!git clone --depth=1 --filter=blob:none --sparse https://github.com/raulcastillabravo/datasets.git\n","%cd datasets\n","!git sparse-checkout set renfe/passengers/ renfe/stations/\n","%cd ..\n","\n","import os\n","import sys\n","from datetime import datetime\n","# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n","\n","\n","import findspark\n","findspark.init()\n","findspark.find()\n","\n","import pyspark\n","\n","from pyspark.sql import DataFrame, SparkSession\n","from typing import List\n","import pyspark.sql.types as T\n","import pyspark.sql.functions as F\n","\n","spark= SparkSession \\\n","       .builder \\\n","       .appName(\"Our First Spark Example\") \\\n","       .getOrCreate()\n","\n","spark"]},{"cell_type":"markdown","metadata":{"id":"SPNzdS97iKL0"},"source":["# Esquemas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aWYGWGTjRsVK"},"outputs":[],"source":["PASSENGERS_SCHEMA =  T.StructType([\n","    T.StructField('codigo_estacion', T.IntegerType(), True),\n","    T.StructField('nombre_estacion', T.StringType(), True),\n","    T.StructField('nucleo_cercanias', T.StringType(), True),\n","    T.StructField('tramo_horario', T.StringType(), True),\n","    T.StructField('viajeros_subidos', T.IntegerType(), True),\n","    T.StructField('viajeros_bajados', T.IntegerType(), True),\n","])\n","\n","STATIONS_SCHEMA = T.StructType([\n","    T.StructField(\"codigo_estacion\", T.IntegerType(), True),\n","    T.StructField(\"descripcion\", T.StringType(), True),\n","    T.StructField(\"latitud\", T.DoubleType(), True),\n","    T.StructField(\"longitud\", T.DoubleType(), True),\n","    T.StructField(\"direccion\", T.StringType(), True),\n","    T.StructField(\"cp\", T.StringType(), True),\n","    T.StructField(\"poblacion\", T.StringType(), True),\n","    T.StructField(\"provincia\", T.StringType(), True),\n","    T.StructField(\"fichas\", T.StringType(), True),\n","    T.StructField(\"tuneles_lavado\", T.StringType(), True),\n","])"]},{"cell_type":"markdown","metadata":{"id":"jTjMwch6iX2S"},"source":["# Lectura"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8omzi81fOQ-"},"outputs":[],"source":["df_passengers = spark.read.csv('/content/datasets/renfe/passengers/', sep=';', header=True, schema=PASSENGERS_SCHEMA)\n","df_stations = spark.read.csv('/content/datasets/renfe/stations/', sep=';', header=True, schema=STATIONS_SCHEMA)"]},{"cell_type":"markdown","metadata":{"id":"vrciin4CbJSY"},"source":["# Ejercicio 1\n","\n","Escribe la tabla **passengers** particionada por la primera hora del tramo horario. Si **tramo_horario** es 09:00 - 09:30, la partición debe ser **tramo_inicio=0900**\n","\n","**Funciones útiles**\n","\n","```\n","F.split(F.col('colname'), ',')[0]  # divide los valores por coma y extrae el primero\n","F.regexp_replace(F.col('colname'), ',', ';')  # Cambia las comas por puntos y comas\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":254,"status":"ok","timestamp":1729412808402,"user":{"displayName":"Raúl Castilla Bravo","userId":"13852866943844834266"},"user_tz":-120},"id":"zQSDR5Xm0Va4"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"YKYC3vvXdLRc"},"source":["# Ejercicio 2\n","\n","Calcula el total de viajeros que han subido y bajado por núcleo de cercanías\n","\n","**Funciones útiles**\n","\n","\n","```\n","F.sum(F.col('colname)).alias('new_colname') # Permite sumar los valores de una columna\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":235,"status":"ok","timestamp":1729412812047,"user":{"displayName":"Raúl Castilla Bravo","userId":"13852866943844834266"},"user_tz":-120},"id":"53fzCEVB099o"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"mKeqmBN2epYp"},"source":["# Ejercicio 3\n","\n","Filtra los tramos horarios que tengan como **hora de inicio una hora en punto**. Si el tramo horario es 00:00 - 00:30, sí lo queremos, pero si es 00:30 - 01:00, no.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1729412823154,"user":{"displayName":"Raúl Castilla Bravo","userId":"13852866943844834266"},"user_tz":-120},"id":"n7AKP65-1LD3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"fVPQvXnNgJz5"},"source":["# Ejercicio 4\n","\n","Calcula cuántos viajeros se suben a los trenes en cada población y ordena el resultado de mayor a menor.\n","\n","**Pista**: tendrás que cruzar (**join**) la tabla de pasajeros con la de estaciones, agrupar y sumar. Puedes ordenar el resultado final usando **orderBy** de la siguiente forma\n","\n","\n","```\n","df.orderBy(F.col('colname'), ascending=False)  # Ordena de forma descendente\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":252,"status":"ok","timestamp":1729412827082,"user":{"displayName":"Raúl Castilla Bravo","userId":"13852866943844834266"},"user_tz":-120},"id":"dejwusw81vDM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"hLJ19bRoi20Y"},"source":["# Ejercicio 5 (micro proyecto)\n","\n","Se ha detectado que en la tabla de estaciones hay fichas que están vacías (**NULL**). Se quiere evaluar el impacto de estas fichas vacías para saber a cuántos pasajeros les está afectando.\n","\n","Para ello, se pide realizar un proceso automático que genere un informe con las siguientes características:\n","\n","1. Debe mostrar la información agrupada por núcleo de cercanías.\n","2. Debe calcular dos KPIs:\n","  1. El porcentaje de viajeros que han subido a un tren sin ficha.\n","  2. El número de viajeros que han subido a un tren sin ficha.\n","3. El resultado debe estar ordenado de mayor a menor porcentaje.\n","4. El resultado debe escribirse particionado por núcleo de cercanías.\n","5. Cada vez que se ejecute el proceso, debe crearse una partición nueva con los resultados de la ejecución para poder tener trazabilidad de análisis anteriores.\n","\n","**Pistas**\n","\n","```\n","df.filter(F.col('colname').isNull())  # Filtra los valores NULL\n","df.filter(F.col('colname').isNotNull())  # Filtra los valores no NULL\n","\n","\n","# Permite crear una marca de tiempo con el instante de ejecucion\n","from datetime import datetime\n","now = datetime.now().strftime(\"%Y%m%d%H%M%S\") # El resultado es un string\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XdeSeL1KqZiE"},"source":["## Fase 1.\n","\n","1. Cruzar tabla **df_passengers** con **df_station**.\n","2. Filtrar los casos donde las fichas son nulas y donde no lo son para crear dos DataFrames llamados **df_null** y **df_not_null**."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":388,"status":"ok","timestamp":1729412842026,"user":{"displayName":"Raúl Castilla Bravo","userId":"13852866943844834266"},"user_tz":-120},"id":"y8hUTmhr2s7y"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ylsfoTxeqwDs"},"source":["## Fase 2.\n","\n","Agrupar cada DataFrame por separado para contar el número de viajeros subidos."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":237,"status":"ok","timestamp":1729412855686,"user":{"displayName":"Raúl Castilla Bravo","userId":"13852866943844834266"},"user_tz":-120},"id":"CKqVDqEx3X0B"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"IDnRMDfLq3YX"},"source":["## Fase 3\n","\n","Cruzar los resultados agregados y calcular el porcentaje de viajeros sin ficha"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":237,"status":"ok","timestamp":1729412861222,"user":{"displayName":"Raúl Castilla Bravo","userId":"13852866943844834266"},"user_tz":-120},"id":"zvmno0GZ3rRD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ee9ceQM8q_XW"},"source":["## Fase 4\n","\n","Escribir el resultado final particionado por fecha de ejecución y núcleo de cercanías"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2nnIQAMpSZ9"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOwdKbXmxn4+7CY38Iv6wGn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
